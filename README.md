# ğŸ‘ï¸ **EYE-ASSISST**

### AI-Powered Eye Disease Detection & Clinical Decision Support Platform

> **An end-to-end medical imaging ML system for early eye-disease screening â€” designed with clinical rigor, external validation, and human-in-the-loop safety.**

âš ï¸ **Medical Disclaimer**
This project is strictly for **educational and research purposes**.
It **does not provide medical diagnosis or prescriptions**.
All final decisions must be made by **licensed ophthalmologists**.

---

## ğŸŒ Why This Project Exists

Eye diseases like **Diabetic Retinopathy (DR)** often progress silently.
Delayed detection leads to irreversible vision loss.

**EYE-ASSISST** is built to:

* ğŸ§  Enable **early AI-assisted screening**
* ğŸ‘¨â€âš•ï¸ Support clinicians with **data-driven insights**
* ğŸ” Prioritize **generalization over inflated metrics**
* âš–ï¸ Follow **ethical & explainable AI principles**

This is **not a demo CNN** â€” it is a **research-grade medical ML system**.

---

## ğŸš€ Project Roadmap & Status

| Phase        | Description                        | Status               |
| ------------ | ---------------------------------- | -------------------- |
| **Phase 1A** | Data Engineering                   | âœ… Completed          |
| **Phase 1B** | Medical Image Preprocessing        | âœ… Completed          |
| **Phase 2A** | CNN Strategy & Clinical Design     | âœ… Completed          |
| **Phase 2B** | CNN Training & External Validation | âœ… Completed & Frozen |
| **Phase 3**  | Multi-Disease AI System            | ğŸŸ¡ Planning          |

---

## ğŸ§  Core Features

### âœ… Implemented (Phase 2)

* Binary DR screening (NORMAL vs DR)
* CNN-based retinal image classification
* External dataset validation (APTOS)
* Clinically prioritized metrics
* Strict data-leakage prevention
* Reproducible ML pipeline

### ğŸ”œ Planned (Phase 3+)

* Multi-disease classification
* Explainability (Grad-CAM)
* Doctor approval workflow
* NLP symptom assistant
* Real-time inference & deployment

---

## ğŸ—‚ï¸ Repository Structure (Phase 2)

```
eye-assisst/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/        # Frozen DataModule & splits
â”‚   â”œâ”€â”€ models/      # CNN backbone (ResNet-18)
â”‚   â”œâ”€â”€ training/    # Training & evaluation logic
â”‚   â”œâ”€â”€ metrics/     # Medical metrics (Sensitivity, AUC)
â”‚   â””â”€â”€ utils/       # Reproducibility helpers
â”œâ”€â”€ notebooks/       # Phase results & analysis
â”œâ”€â”€ models/          # Checkpoints (Git LFS)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

ğŸ”’ **Medical datasets are intentionally excluded from GitHub**.

---

## ğŸ“Š Datasets Used

### Primary Dataset

* **EyePACS**
  Large-scale retinal fundus dataset used for **training & validation**.

### External Test Dataset

* **APTOS**
  Used **only for final evaluation** to measure real-world generalization.

> No image from APTOS was ever seen during training or tuning.

---

## ğŸ§ª How to Run (Development)

```bash
# 1ï¸âƒ£ Clone repository
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>

# 2ï¸âƒ£ Create environment
python -m venv venv
source venv/bin/activate     # Linux / Mac
venv\Scripts\activate        # Windows

# 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
```

---

# ğŸ§  Phase 2 â€” The Heart of This Project

## ğŸ”’ Phase Freeze Guarantee

Before Phase 2 began, **Phase 1 was permanently frozen**:

* âœ… Data ingestion finalized
* âœ… Preprocessing finalized
* âœ… Train / Val / Test splits finalized
* âœ… Manifest CSV locked

ğŸš« **No changes allowed** during Phase 2
This ensures **zero data leakage** and **reproducible experiments**.

---

## ğŸ§  Phase 2A â€” CNN Strategy & Clinical Design

> *â€œThink like an ML engineer before writing code.â€*

Phase 2A focuses on **decision-making, not training**.

### ğŸ¯ Objective

Design a **clinically meaningful and generalizable DR screening system**, not just a high-accuracy model.

### ğŸ§© Key Decisions (Locked)

#### 1ï¸âƒ£ Binary vs Multi-Class Classification

* **Chosen:** NORMAL vs DR
* **Why:**

  * Screening relevance
  * Severity labels are noisy
  * Better external generalization

---

#### 2ï¸âƒ£ Loss Functions for Medical AI

Options evaluated:

* Binary Cross Entropy
* BCE with Class Weights âœ…
* Focal Loss

**Clinical logic:**
False negatives (missing DR) are more dangerous than false positives.

---

#### 3ï¸âƒ£ Metrics Beyond Accuracy

Primary metric:

* â­ **Sensitivity (Recall for DR)**

Supporting metrics:

* Specificity
* AUC-ROC
* Precisionâ€“Recall trade-off

Accuracy alone is misleading in medical datasets.

---

#### 4ï¸âƒ£ Class Imbalance Handling

Strategies compared:

* Class weighting âœ…
* Over/Under-sampling

**Why no resampling at split time?**
To preserve **real-world disease prevalence**.

---

#### 5ï¸âƒ£ Training Protocol: EyePACS â†’ APTOS

* Train + validate on EyePACS
* Test only on APTOS

This elevates the project from:

> â€œI trained a CNNâ€
> to
> **â€œI evaluated real generalization.â€**

---

## ğŸ¤– AI-Augmented ML Workflow

Used responsibly:

* **ChatGPT** â†’ Strategy & reasoning
* **Perplexity AI** â†’ Evidence validation
* **Notion / Markdown** â†’ Decision logs
* **Cursor** â†’ Implementation
* **Weights & Biases** â†’ Experiment tracking

AI enhanced thinking â€” it never replaced fundamentals.

---

## ğŸ§  Phase 2B â€” Implementation & Training

### ğŸ§© Model Architecture

* **CNN Backbone:** ResNet-18
* ImageNet pretrained
* Single backbone enforced for Phase 2

### ğŸ§© Training Setup

* Optimizer: AdamW
* LR Scheduler
* Early stopping on **validation sensitivity**
* Best model saved by **clinical priority**, not accuracy

---

## ğŸ“Š Phase 2 Results â€” External Validation (APTOS)

â­ **This is the most important result of the project**

| Metric                  | Value        |
| ----------------------- | ------------ |
| Accuracy                | ~95.9%       |
| Sensitivity (DR Recall) | **~96.4%** â­ |
| Specificity             | ~95.4%       |
| AUC-ROC                 | ~0.988       |

### ğŸ§ª Confusion Matrix (APTOS)

* True Positives: **348**
* False Negatives: **13**
* False Positives: **17**
* True Negatives: **355**

---

## ğŸ©º Clinical Interpretation

* ğŸ”¥ Very low false-negative rate
* âš–ï¸ Balanced performance across classes
* ğŸŒ Strong generalization to unseen data

The model learned **disease-relevant features**, not dataset shortcuts.

---

## ğŸ“ˆ Why Training Curves Are Not Emphasized

* External generalization > fitting dynamics
* Early stopping occurred naturally
* Final metrics provide stronger clinical evidence

This aligns with **research-grade medical ML practice**.

---

## ğŸ”’ Phase 2 Closure Statement

Phase 2 is **officially complete and frozen**.

âœ” External validation achieved
âœ” No test-set tuning
âœ” Clinically meaningful metrics
âœ” Clean experiment discipline

---

## ğŸ”œ Phase 3 â€” Multi-Disease Medical AI (Planning)

Planned extensions:

* Multi-label disease detection
* Shared backbone + disease heads
* Grad-CAM explainability
* Real-time inference

ğŸ“Œ **Phase 3 has not started yet**

---

## ğŸ Final Note

> In medical AI,
> **honest generalization beats perfect numbers.**

This project prioritizes **trustworthy ML** over inflated benchmarks.

---

## ğŸ‘¤ Author

**Siddhanth Sharma**
B.Tech â€” Machine Learning & AI
Focused on **applied medical AI**, **ML engineering**, and **real-world systems**

---
