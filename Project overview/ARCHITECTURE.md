# üèóÔ∏è EYE-ASSISST Project Architecture

> **Complete architectural documentation for the Eye Disease Detection & Clinical Decision Support Platform**

---

## üìê System Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        EYE-ASSISST PLATFORM                          ‚îÇ
‚îÇ              AI-Powered Eye Disease Detection System                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Phase 1    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Phase 2    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Phase 3    ‚îÇ
‚îÇ  Binary DR   ‚îÇ    ‚îÇ DR Severity  ‚îÇ    ‚îÇ Multi-Task   ‚îÇ
‚îÇ Classification‚îÇ    ‚îÇ   Grading    ‚îÇ    ‚îÇ  Learning    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                    ‚îÇ                    ‚îÇ
      ‚ñº                    ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Shared Components: Data, Models, Training, Utils    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Directory Structure & Component Roles

### **ROOT LEVEL**

```
eye-realtime-inference/
‚îÇ
‚îú‚îÄ‚îÄ üìú train.py                    [MAIN] Entry point for Phase-1 binary DR training
‚îú‚îÄ‚îÄ üìú evaluate.py                 [MAIN] Entry point for Phase-1 model evaluation
‚îú‚îÄ‚îÄ üìÑ README.md                   [DOC]  Project overview, setup instructions
‚îú‚îÄ‚îÄ üìÑ IMPROVEMENTS.md             [DOC]  Code analysis & improvement logs
‚îú‚îÄ‚îÄ üìÑ ARCHITECTURE.md             [DOC]  ‚≠ê THIS FILE - Complete architecture guide
‚îú‚îÄ‚îÄ üìÑ requirements.txt            [CFG]  Python dependencies (PyTorch, CV libs, etc.)
‚îî‚îÄ‚îÄ üìÑ trainLabels.csv             [DATA] Legacy/backup labels file
```

**Purpose:**
- **Entry Points:** `train.py` & `evaluate.py` orchestrate Phase-1 training/evaluation
- **Documentation:** README for users, IMPROVEMENTS for dev logs, ARCHITECTURE for system design
- **Config:** `requirements.txt` manages all dependencies

---

### **üìÇ `configs/` - Configuration Files**

```
configs/
‚îú‚îÄ‚îÄ model.yaml                     [EMPTY] ‚ö†Ô∏è Placeholder for model hyperparameters
‚îú‚îÄ‚îÄ paths.yaml                     [EMPTY] ‚ö†Ô∏è Placeholder for data paths config
‚îî‚îÄ‚îÄ train.yaml                     [EMPTY] ‚ö†Ô∏è Placeholder for training settings
```

**Purpose:**
- Centralized YAML configs for model architecture, data paths, training hyperparameters
- **Status:** Currently empty - ready for future structured configuration

**Usage:** Load configs in training scripts for reproducibility & easy experimentation

---

### **üìÇ `Data/` - All Dataset Storage**

```
Data/
‚îú‚îÄ‚îÄ raw/                           [DATA] Original unprocessed datasets
‚îÇ   ‚îú‚îÄ‚îÄ all-images/                       MESSIDOR dataset (im0001.ppm - im1200.ppm)
‚îÇ   ‚îú‚îÄ‚îÄ AMD (Age-related Macular Degeneration)/
‚îÇ   ‚îú‚îÄ‚îÄ Aptos/                            APTOS 2019 Blindness Detection dataset
‚îÇ   ‚îú‚îÄ‚îÄ Cataract (External Eye Images)/
‚îÇ   ‚îú‚îÄ‚îÄ EYE-Pacs Dataset/                 EyePACS (Kaggle DR Competition)
‚îÇ   ‚îî‚îÄ‚îÄ ODIR Dataset/                     Ocular Disease Intelligent Recognition
‚îÇ
‚îú‚îÄ‚îÄ cleaned/                       [DATA] Cleaned/filtered datasets
‚îÇ   ‚îú‚îÄ‚îÄ external/                         External eye images (cataract, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ fundus/                           Fundus images only
‚îÇ       ‚îú‚îÄ‚îÄ DR/                           Contains DR-positive fundus images
‚îÇ       ‚îî‚îÄ‚îÄ NORMAL/                       Contains healthy fundus images
‚îÇ
‚îú‚îÄ‚îÄ processed/                     [DATA] Preprocessed & standardized images
‚îÇ   ‚îî‚îÄ‚îÄ fundus/
‚îÇ       ‚îú‚îÄ‚îÄ aptos/                        APTOS preprocessed (resizing, normalization)
‚îÇ       ‚îî‚îÄ‚îÄ eyepacs/                      EyePACS preprocessed
‚îÇ
‚îú‚îÄ‚îÄ splits/                        [DATA] ‚≠ê FROZEN TRAIN/VAL/TEST SPLITS (Phase-1)
‚îÇ   ‚îî‚îÄ‚îÄ fundus/
‚îÇ       ‚îú‚îÄ‚îÄ eyepacs/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ train/                    Training set (DR/, NORMAL/)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ val/                      Validation set (DR/, NORMAL/)
‚îÇ       ‚îî‚îÄ‚îÄ aptos/
‚îÇ           ‚îî‚îÄ‚îÄ test/                     External test set (DR/, NORMAL/)
‚îÇ
‚îú‚îÄ‚îÄ labels/                        [DATA] CSV label files
‚îÇ   ‚îú‚îÄ‚îÄ aptos_test.csv                    APTOS test labels
‚îÇ   ‚îú‚îÄ‚îÄ aptos_train.csv                   APTOS training labels
‚îÇ   ‚îî‚îÄ‚îÄ eyepacs_trainLabels.csv           EyePACS original labels (image, level)
‚îÇ
‚îî‚îÄ‚îÄ metadata/                      [DATA] Dataset statistics & manifest
    ‚îî‚îÄ‚îÄ data_manifest.csv                 Complete data inventory
```

**Data Flow:**
1. **Raw** ‚Üí Original downloaded datasets
2. **Cleaned** ‚Üí Quality filtering, format standardization
3. **Processed** ‚Üí Resized, normalized, ready for model input
4. **Splits** ‚Üí Final train/val/test folders (used by dataloaders)

**Key Notes:**
- `splits/` contains **FROZEN** splits for reproducibility
- `labels/` stores severity grades (0-4) for EyePACS DR staging
- `cleaned/fundus/` separates fundus vs external eye images

---

### **üìÇ `models/` - Trained Model Checkpoints**

```
models/
‚îú‚îÄ‚îÄ binary_dr/                     [MODELS] Phase-1 binary DR classifier
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pt                     Best checkpoint (highest val metric)
‚îÇ   ‚îú‚îÄ‚îÄ best.pt                           Alternative best model
‚îÇ   ‚îú‚îÄ‚îÄ latest.pt                         Most recent epoch checkpoint
‚îÇ   ‚îî‚îÄ‚îÄ training_history.json             Loss/metric curves
‚îÇ
‚îî‚îÄ‚îÄ stage1_dr_binary/              [MODELS] Stage-1 multi-model training
    ‚îú‚îÄ‚îÄ best_model.pt
    ‚îú‚îÄ‚îÄ best.pt
    ‚îú‚îÄ‚îÄ latest.pt
    ‚îî‚îÄ‚îÄ training_history.json
```

**Purpose:**
- Save trained model weights for inference & retraining
- Track training history (loss/accuracy curves) via JSON logs

**Checkpoint Strategy:**
- `best.pt`: Saved when validation metric improves
- `latest.pt`: Saved every N epochs for recovery
- `training_history.json`: Plotted for convergence analysis

---

### **üìÇ `notebooks/` - Jupyter Experimentation**

```
notebooks/
‚îú‚îÄ‚îÄ phase1b/                       [ANALYSIS] Phase-1 exploratory analysis
‚îÇ   ‚îú‚îÄ‚îÄ 01_inspect_images.ipynb            EDA: Image quality, class distribution
‚îÇ   ‚îî‚îÄ‚îÄ 01_inspect_aptos.ipynb             APTOS dataset exploration
‚îÇ
‚îú‚îÄ‚îÄ phase 2/                       [RESULTS] Phase-2 severity grading results
‚îÇ   ‚îî‚îÄ‚îÄ phase2_results.ipynb               DR severity model evaluation
‚îÇ
‚îî‚îÄ‚îÄ phase 3/                       [DEBUG] Phase-3 multi-task debugging
    ‚îî‚îÄ‚îÄ head_checker.ipynb                 Verify multi-head model outputs
```

**Purpose:**
- **Phase 1b:** Data quality checks, distribution analysis, baseline metrics
- **Phase 2:** Evaluate DR severity grading (0-4 scale)
- **Phase 3:** Debug multi-task model (binary + severity + multi-label heads)

**Usage:** Interactive exploration, visualization, hypothesis testing before production code

---

### **üìÇ `scripts/` - Data Preprocessing & Utilities**

```
scripts/
‚îú‚îÄ‚îÄ spliteyepacs.py                [SCRIPT] Split EyePACS into train/val/test
‚îÇ
‚îú‚îÄ‚îÄ preprocessing/                 [SCRIPTS] Data preparation pipelines
‚îÇ   ‚îú‚îÄ‚îÄ count.py                           Count images per class
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_aptos.py                Resize/normalize APTOS images
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_eyepacs.py              Resize/normalize EyePACS images
‚îÇ   ‚îú‚îÄ‚îÄ split_aptos.py                     Split APTOS into test set
‚îÇ   ‚îî‚îÄ‚îÄ split_train_val_test.py            Generic train/val/test splitter
‚îÇ
‚îî‚îÄ‚îÄ metadata_code/                 [SCRIPTS] Dataset metadata generation
    ‚îî‚îÄ‚îÄ build_manifest.py                  Create data_manifest.csv inventory
```

**Purpose:**
- **Preprocessing:** Convert raw images ‚Üí processed images (resize, normalize, crop)
- **Splitting:** Create reproducible train/val/test splits
- **Metadata:** Track data provenance, counts, quality metrics

**Run Order:**
1. `preprocess_*.py` ‚Üí Clean raw images
2. `split_*.py` ‚Üí Create frozen splits
3. `build_manifest.py` ‚Üí Generate metadata CSV

---

### **üìÇ `src/` - Core ML Pipeline (Modular Design)**

```
src/
‚îú‚îÄ‚îÄ __init__.py                    [MODULE] Make src a Python package
‚îÇ
‚îú‚îÄ‚îÄ configs/                       [CFG] Training stage configurations
‚îÇ   ‚îú‚îÄ‚îÄ base.yml                           [EMPTY] ‚ö†Ô∏è Base config template
‚îÇ   ‚îú‚îÄ‚îÄ stage1_dr.yaml                     [EMPTY] ‚ö†Ô∏è Stage-1 DR binary config
‚îÇ   ‚îú‚îÄ‚îÄ stage2_mutlilabel.yml              [EMPTY] ‚ö†Ô∏è Stage-2 multi-label config
‚îÇ   ‚îî‚îÄ‚îÄ stage3_joint.yaml                  [EMPTY] ‚ö†Ô∏è Stage-3 joint training config
‚îÇ
‚îú‚îÄ‚îÄ data/                          [MODULE] ‚≠ê Dataset handling & augmentation
‚îú‚îÄ‚îÄ models/                        [MODULE] ‚≠ê Neural network architectures
‚îú‚îÄ‚îÄ training/                      [MODULE] ‚≠ê Training & evaluation loops
‚îú‚îÄ‚îÄ losses/                        [MODULE] ‚≠ê Custom loss functions
‚îú‚îÄ‚îÄ metrics/                       [MODULE] ‚≠ê Evaluation metrics
‚îú‚îÄ‚îÄ utils/                         [MODULE] ‚≠ê Utilities (logging, checkpoints, etc.)
‚îú‚îÄ‚îÄ explainability/                [MODULE] ‚≠ê Grad-CAM & interpretability
‚îú‚îÄ‚îÄ training phase 3(multi-model)/ [MODULE] ‚≠ê Phase-3 multi-model training
‚îî‚îÄ‚îÄ evaluation phase 3(multi-model)/ [MODULE] ‚≠ê Phase-3 evaluation
```

---

#### **üìÇ `src/data/` - Dataset & DataModule**

```
src/data/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ datamodule.py                  [CLASS] FundusDataModule (Phase-1 binary DR)
‚îú‚îÄ‚îÄ eyepacs_severity_datamodule.py [CLASS] EyePACSSeverityDataModule (Phase-2)
‚îú‚îÄ‚îÄ transforms.py                  [UTILS] Custom image augmentations
‚îÇ
‚îî‚îÄ‚îÄ datasets/                      [DATASETS] PyTorch Dataset classes
    ‚îú‚îÄ‚îÄ eyepacs_severity.py                ‚úÖ EyePACS with severity labels (0-4)
    ‚îú‚îÄ‚îÄ eyepacs.py                         [EMPTY] ‚ö†Ô∏è Placeholder for EyePACS binary
    ‚îú‚îÄ‚îÄ aptos.py                           [EMPTY] ‚ö†Ô∏è Placeholder for APTOS dataset
    ‚îú‚îÄ‚îÄ amd.py                             [EMPTY] ‚ö†Ô∏è Placeholder for AMD dataset
    ‚îú‚îÄ‚îÄ cataract.py                        [EMPTY] ‚ö†Ô∏è Placeholder for cataract dataset
    ‚îî‚îÄ‚îÄ odir.py                            [EMPTY] ‚ö†Ô∏è Placeholder for ODIR dataset
```

**Key Components:**

| File | Purpose | Status |
|------|---------|--------|
| `datamodule.py` | Binary DR classification dataloader (EyePACS train/val, APTOS test) | ‚úÖ Active |
| `eyepacs_severity_datamodule.py` | DR severity grading (0-4) dataloader | ‚úÖ Active |
| `transforms.py` | Custom augmentations (rotation, crop, color jitter) | ‚úÖ Active |
| `datasets/eyepacs_severity.py` | EyePACS Dataset returning `(image, dr_label, severity_label)` | ‚úÖ Active |
| `datasets/*.py` (others) | Future multi-disease datasets | ‚ö†Ô∏è Empty placeholders |

**Data Flow:**
```
Raw Images ‚Üí Dataset Class ‚Üí DataModule ‚Üí DataLoader ‚Üí Model
              ‚Üì                  ‚Üì              ‚Üì
        Augmentation      Train/Val Split  Batching
```

---

#### **üìÇ `src/models/` - Neural Network Architectures**

```
src/models/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ cnn_backbone.py                [CLASS] Generic CNN feature extractor
‚îú‚îÄ‚îÄ multi_task_models.py           [CLASS] Multi-task model (shared backbone + multiple heads)
‚îÇ
‚îú‚îÄ‚îÄ backbone/                      [BACKBONES] Feature extraction networks
‚îÇ   ‚îî‚îÄ‚îÄ resnet.py                          ResNetBackbone (ResNet18/50/101)
‚îÇ
‚îî‚îÄ‚îÄ heads/                         [HEADS] Task-specific output layers
    ‚îú‚îÄ‚îÄ dr_binary.py                       Binary DR classification head (1 output)
    ‚îú‚îÄ‚îÄ dr_severity.py                     DR severity grading head (5 classes: 0-4)
    ‚îî‚îÄ‚îÄ multi_label.py                     Multi-label disease classification head
```

**Architecture Pattern:**
```
Input Image
     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Backbone   ‚îÇ ‚Üê Shared feature extractor (ResNet, EfficientNet)
‚îÇ (ResNet50)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚Üì [Features: 2048-dim]
     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚ñº             ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Binary  ‚îÇ  ‚îÇ Severity ‚îÇ  ‚îÇ Multi-Label ‚îÇ
‚îÇ  Head   ‚îÇ  ‚îÇ   Head   ‚îÇ  ‚îÇ    Head     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ             ‚îÇ             ‚îÇ
     ‚ñº             ‚ñº             ‚ñº
  DR/Normal    Grade 0-4    AMD/Cataract/etc.
```

**Key Files:**

| File | Purpose | Architecture |
|------|---------|--------------|
| `cnn_backbone.py` | Generic CNN wrapper | ResNet/EfficientNet/VGG |
| `multi_task_models.py` | Multi-task architecture | Shared backbone + 3 heads |
| `backbone/resnet.py` | ResNet variants | ResNet18/50/101/152 |
| `heads/dr_binary.py` | Binary classification | FC layer (2048 ‚Üí 1 sigmoid) |
| `heads/dr_severity.py` | 5-class severity | FC layer (2048 ‚Üí 5 softmax) |
| `heads/multi_label.py` | Multi-label (8 diseases) | FC layer (2048 ‚Üí 8 sigmoid) |

**Design Principles:**
- **Modularity:** Swap backbones without changing heads
- **Pretrained Weights:** ImageNet initialization for transfer learning
- **Multi-Task Learning:** Share low-level features, specialize high-level heads

---

#### **üìÇ `src/training/` - Training & Evaluation**

```
src/training/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ train_binary.py                [CLASS] BinaryTrainer for Phase-1 DR classification
‚îú‚îÄ‚îÄ evaluate.py                    [CLASS] BinaryEvaluator for Phase-1 evaluation
‚îú‚îÄ‚îÄ run_train.py                   [SCRIPT] Training orchestration script
‚îî‚îÄ‚îÄ run_eval.py                    [SCRIPT] Evaluation orchestration script
```

**Purpose:**
- **Trainer Classes:** Encapsulate training loops, validation, checkpointing
- **Evaluator Classes:** Compute metrics (accuracy, sensitivity, specificity, AUC)
- **Run Scripts:** CLI interfaces for training/evaluation

**Training Loop Structure:**
```python
for epoch in range(num_epochs):
    # Training phase
    for batch in train_dataloader:
        loss = model(batch)
        loss.backward()
        optimizer.step()
    
    # Validation phase
    metrics = evaluate(model, val_dataloader)
    
    # Checkpointing
    if metrics['auc'] > best_auc:
        save_checkpoint(model, 'best.pt')
```

**Key Metrics:**
- **Binary DR:** Accuracy, Sensitivity (Recall), Specificity, AUC-ROC
- **Severity:** Quadratic Weighted Kappa (QWK), Confusion Matrix
- **Multi-Label:** Per-disease AUC, F1-score, Hamming Loss

---

#### **üìÇ `src/losses/` - Custom Loss Functions**

```
src/losses/
‚îú‚îÄ‚îÄ masked_bce.py                  [LOSS] Masked Binary Cross-Entropy (ignore missing labels)
‚îî‚îÄ‚îÄ severity_loss.py               [LOSS] Ordinal regression loss for DR severity (0-4)
```

**Purpose:**
- **Masked BCE:** Handle multi-label datasets with missing annotations (ODIR, etc.)
- **Severity Loss:** Penalize severity prediction errors proportional to grade difference
  - Example: Predicting Grade 1 when truth is Grade 3 is worse than Grade 2 vs 3

**Severity Loss (Ordinal Regression):**
```python
# Traditional Cross-Entropy: Treats classes as independent
# Problem: Predicting 0 when truth is 4 is same penalty as 3 vs 4

# Ordinal Loss: Penalizes based on distance
# Penalty(pred=0, true=4) > Penalty(pred=3, true=4)
```

---

#### **üìÇ `src/metrics/` - Evaluation Metrics**

```
src/metrics/
‚îú‚îÄ‚îÄ __init__.py
‚îî‚îÄ‚îÄ metrics.py                     [METRICS] Medical imaging metrics (Sensitivity, Specificity, AUC, QWK)
```

**Medical Metrics:**

| Metric | Purpose | Formula |
|--------|---------|---------|
| **Sensitivity** (Recall) | Catch all DR cases | TP / (TP + FN) |
| **Specificity** | Avoid false alarms | TN / (TN + FP) |
| **AUC-ROC** | Overall discrimination | Area under ROC curve |
| **QWK** (Kappa) | Severity grading agreement | Weighted Cohen's Kappa |
| **F1-Score** | Balanced precision-recall | 2 √ó (P √ó R) / (P + R) |

**Why These Metrics?**
- In medical screening, **Sensitivity > Accuracy** (missing a DR case is worse than false alarm)
- **Specificity** balances to reduce unnecessary follow-ups
- **QWK** accounts for ordinal nature of severity grades

---

#### **üìÇ `src/utils/` - Shared Utilities**

```
src/utils/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ checkpoints.py                 [UTILS] Save/load model checkpoints
‚îú‚îÄ‚îÄ logging.py                     [UTILS] Training logs (TensorBoard, CSV, console)
‚îî‚îÄ‚îÄ seed.py                        [UTILS] Set random seeds for reproducibility
```

**Purpose:**
- **Checkpointing:** Save model + optimizer state, resume training
- **Logging:** Track loss/metrics over time, visualize with TensorBoard
- **Seeding:** Ensure reproducible experiments (`torch.manual_seed`, `np.random.seed`)

**Reproducibility Setup:**
```python
from src.utils.seed import set_seed
set_seed(42)  # Sets seeds for Python, NumPy, PyTorch, CUDA
```

---

#### **üìÇ `src/explainability/` - Model Interpretability**

```
src/explainability/
‚îî‚îÄ‚îÄ gradcam.py                     [VIZ] Grad-CAM visualization for CNN models
```

**Purpose:**
- **Grad-CAM:** Generate heatmaps showing which image regions influence predictions
- **Clinical Trust:** Verify model looks at optic disc, retina (not image borders, artifacts)

**Example Output:**
```
Original Image ‚Üí Model ‚Üí Grad-CAM Heatmap (red = high attention)
[Shows model focuses on hemorrhages, exudates in DR images]
```

---

#### **üìÇ `src/training phase 3(multi-model)/` - Phase-3 Multi-Model Training**

```
src/training phase 3(multi-model)/
‚îú‚îÄ‚îÄ train_stage1.py                [TRAINER] Stage-1: Train DR binary head only
‚îú‚îÄ‚îÄ train_stage2.py                [TRAINER] Stage-2: Train DR severity head (freeze binary)
‚îú‚îÄ‚îÄ train_stage3.py                [TRAINER] Stage-3: Joint training (all heads)
‚îî‚îÄ‚îÄ trainer.py                     [CLASS] Unified trainer for multi-task models
```

**Multi-Stage Training Strategy:**

| Stage | Goal | Frozen Layers | Active Heads |
|-------|------|---------------|--------------|
| **Stage 1** | Binary DR detection | None | Binary head |
| **Stage 2** | DR severity grading | Backbone + Binary head | Severity head |
| **Stage 3** | Joint optimization | None (fine-tune all) | All heads |

**Why Staged Training?**
1. **Stage 1:** Learn discriminative features for DR vs Normal
2. **Stage 2:** Learn severity features without forgetting binary task
3. **Stage 3:** Fine-tune end-to-end for optimal multi-task performance

---

#### **üìÇ `src/evaluation phase 3(multi-model)/` - Phase-3 Evaluation**

```
src/evaluation phase 3(multi-model)/
‚îú‚îÄ‚îÄ dr_binary_meterics.py          [EVAL] Binary DR metrics (Sensitivity, Specificity, AUC)
‚îú‚îÄ‚îÄ severity_metrics.py            [EVAL] Severity grading metrics (QWK, confusion matrix)
‚îî‚îÄ‚îÄ multilabel_metrics.py          [EVAL] Multi-label disease metrics (per-class AUC, F1)
```

**Purpose:**
- Compute task-specific metrics for multi-task model
- Generate confusion matrices, ROC curves, calibration plots
- Ensure no catastrophic forgetting (binary performance drops when adding severity head)

---

## üîÑ Complete Training Pipeline Flow

### **Phase 1: Binary DR Classification**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              PHASE 1: BINARY DR DETECTION           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. Data Preparation
   ‚îî‚îÄ Run: scripts/preprocessing/preprocess_eyepacs.py
   ‚îî‚îÄ Run: scripts/preprocessing/split_train_val_test.py
   ‚îî‚îÄ Output: Data/splits/fundus/eyepacs/{train,val}
             Data/splits/fundus/aptos/test

2. Training
   ‚îî‚îÄ Run: python train.py --data_root Data/splits/fundus --epochs 50
   ‚îî‚îÄ Uses: src/data/datamodule.py (FundusDataModule)
   ‚îî‚îÄ Model: ResNet18/50 (from torchvision)
   ‚îî‚îÄ Output: models/binary_dr/best.pt

3. Evaluation
   ‚îî‚îÄ Run: python evaluate.py --checkpoint models/binary_dr/best.pt
   ‚îî‚îÄ Metrics: Accuracy, Sensitivity, Specificity, AUC
   ‚îî‚îÄ Output: Confusion matrix, ROC curve
```

### **Phase 2: DR Severity Grading**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            PHASE 2: DR SEVERITY GRADING             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. Data Preparation
   ‚îî‚îÄ Use: Data/labels/eyepacs_trainLabels.csv (severity 0-4)
   ‚îî‚îÄ DataModule: src/data/eyepacs_severity_datamodule.py

2. Training
   ‚îî‚îÄ Run: src/training phase 3(multi-model)/train_stage2.py
   ‚îî‚îÄ Model: Multi-task model (binary head + severity head)
   ‚îî‚îÄ Strategy: Freeze binary head, train severity head only

3. Evaluation
   ‚îî‚îÄ Run: src/evaluation phase 3(multi-model)/severity_metrics.py
   ‚îî‚îÄ Metrics: Quadratic Weighted Kappa (QWK), Per-class accuracy
```

### **Phase 3: Multi-Task Learning**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         PHASE 3: MULTI-TASK JOINT TRAINING          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. Architecture
   ‚îî‚îÄ Backbone: ResNet50 (shared)
   ‚îî‚îÄ Heads: 
      ‚îú‚îÄ DR Binary (2 classes)
      ‚îú‚îÄ DR Severity (5 classes: 0-4)
      ‚îî‚îÄ Multi-label (8 diseases: AMD, Cataract, etc.)

2. Training Strategy
   ‚îî‚îÄ Stage 1: Train binary head
   ‚îî‚îÄ Stage 2: Add severity head (freeze binary)
   ‚îî‚îÄ Stage 3: Add multi-label head, fine-tune all

3. Loss Function
   ‚îî‚îÄ Total Loss = Œª‚ÇÅ¬∑BinaryLoss + Œª‚ÇÇ¬∑SeverityLoss + Œª‚ÇÉ¬∑MultiLabelLoss
   ‚îî‚îÄ Weights: Œª‚ÇÅ=1.0, Œª‚ÇÇ=0.5, Œª‚ÇÉ=0.3 (tunable)

4. Evaluation
   ‚îî‚îÄ Binary: AUC, Sensitivity, Specificity
   ‚îî‚îÄ Severity: QWK, Confusion Matrix
   ‚îî‚îÄ Multi-label: Per-disease AUC, Hamming Loss
```

---

## ‚ö†Ô∏è Empty Files & Placeholders (Ready for Implementation)

### **Configuration Files (Empty)**
- `configs/model.yaml` ‚ùå
- `configs/paths.yaml` ‚ùå
- `configs/train.yaml` ‚ùå
- `src/configs/base.yml` ‚ùå
- `src/configs/stage1_dr.yaml` ‚ùå
- `src/configs/stage2_mutlilabel.yml` ‚ùå
- `src/configs/stage3_joint.yaml` ‚ùå

**Next Steps:**
- Populate YAML configs with hyperparameters (learning rate, batch size, etc.)
- Enable easy experiment tracking via config files

### **Dataset Classes (Empty Placeholders)**
- `src/data/datasets/eyepacs.py` ‚ùå
- `src/data/datasets/aptos.py` ‚ùå
- `src/data/datasets/amd.py` ‚ùå
- `src/data/datasets/cataract.py` ‚ùå
- `src/data/datasets/odir.py` ‚ùå

**Next Steps:**
- Implement PyTorch Dataset classes for each disease type
- Enable multi-dataset training for robust generalization

---

## üéØ Key Design Principles

### **1. Modularity**
```
‚úÖ Each component is self-contained (datasets, models, trainers)
‚úÖ Swap backbones without changing training code
‚úÖ Add new datasets by implementing Dataset class
```

### **2. Reproducibility**
```
‚úÖ Frozen train/val/test splits (Data/splits/)
‚úÖ Random seed control (src/utils/seed.py)
‚úÖ Model checkpoints saved with optimizer state
‚úÖ Training history logged in JSON
```

### **3. Medical ML Best Practices**
```
‚úÖ External validation (APTOS test set, different source)
‚úÖ Sensitivity > Accuracy (catch DR cases is priority)
‚úÖ Grad-CAM for model interpretability
‚úÖ Ordinal loss for severity grading (respects class ordering)
```

### **4. Scalability**
```
‚úÖ Multi-task learning architecture (shared backbone)
‚úÖ Staged training for incremental learning
‚úÖ Placeholder datasets for future diseases (AMD, Cataract, ODIR)
‚úÖ CLI scripts for easy automation
```

---

## üìä Dataset Summary

| Dataset | Purpose | Images | Classes | Notes |
|---------|---------|--------|---------|-------|
| **EyePACS** | Train/Val | ~35k | Binary (DR/Normal) + Severity (0-4) | Kaggle DR Competition |
| **APTOS** | External Test | ~3.6k | Binary + Severity | APTOS 2019 Blindness Detection |
| **MESSIDOR** | Analysis | ~1.2k | Multi-grade | `Data/raw/all-images/` |
| **AMD** | Future | TBD | AMD detection | Placeholder |
| **Cataract** | Future | TBD | Cataract detection | External eye images |
| **ODIR** | Future | ~8k | 8 diseases (multi-label) | ODIR-5K Challenge |

---

## üöÄ Quick Start Guide

### **1. Environment Setup**
```bash
# Install dependencies
pip install -r requirements.txt

# Verify PyTorch installation
python -c "import torch; print(torch.__version__)"
```

### **2. Phase-1 Training (Binary DR)**
```bash
# Prepare data (if not already split)
python scripts/preprocessing/preprocess_eyepacs.py
python scripts/spliteyepacs.py

# Train binary DR classifier
python train.py --data_root Data/splits/fundus \
                --model resnet18 \
                --epochs 50 \
                --batch_size 32

# Evaluate on APTOS test set
python evaluate.py --checkpoint models/binary_dr/best.pt \
                   --data_root Data/splits/fundus
```

### **3. Phase-2 Training (Severity Grading)**
```bash
# Train severity grading model
python src/training\ phase\ 3\(multi-model\)/train_stage2.py

# Evaluate severity predictions
python src/evaluation\ phase\ 3\(multi-model\)/severity_metrics.py
```

### **4. Grad-CAM Visualization**
```python
from src.explainability.gradcam import GradCAM
import torch

model = torch.load('models/binary_dr/best.pt')
gradcam = GradCAM(model)
heatmap = gradcam.generate(image)
gradcam.visualize(image, heatmap)
```

---

## üìà Future Roadmap

### **Immediate Next Steps**
1. ‚úÖ Populate YAML config files
2. ‚úÖ Implement missing dataset classes (APTOS, AMD, Cataract, ODIR)
3. ‚úÖ Complete Phase-3 multi-task training pipeline
4. ‚úÖ Add ensemble methods (model averaging)

### **Advanced Features**
- ‚è≥ Real-time inference API (FastAPI/Streamlit)
- ‚è≥ Model compression (pruning, quantization for mobile deployment)
- ‚è≥ Active learning for labeling efficiency
- ‚è≥ Federated learning for multi-hospital deployment

---

## üìö References & Standards

- **Medical AI Guidelines:** FDA Software as Medical Device (SaMD)
- **DR Grading Standard:** ICDR (International Clinical Diabetic Retinopathy) Scale
- **Explainability:** Grad-CAM (Selvaraju et al., 2017)
- **Ordinal Regression:** CORAL Loss (Cao et al., 2020)

---

## üìù Version History

| Version | Date | Changes |
|---------|------|---------|
| v1.0 | Feb 2026 | Initial architecture documentation |

---

**Maintained by:** EYE-ASSISST Development Team  
**Last Updated:** February 8, 2026
